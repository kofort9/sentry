#!/bin/bash
# Diagnostic script to check self-hosted runner status

echo "ðŸ” Checking self-hosted runner status for TestSentry"
echo ""

# Check GitHub CLI authentication
echo "1ï¸âƒ£  GitHub CLI Authentication:"
if gh auth status &> /dev/null; then
    echo "   âœ… Authenticated with GitHub CLI"
    USER=$(gh api user --jq '.login')
    echo "   ðŸ‘¤ User: $USER"
else
    echo "   âŒ Not authenticated with GitHub CLI"
    echo "   ðŸ”§ Run: gh auth login"
    exit 1
fi

echo ""

# Check repository access
echo "2ï¸âƒ£  Repository Access:"
if gh repo view kofort9/sentry &> /dev/null; then
    echo "   âœ… Can access kofort9/sentry repository"
else
    echo "   âŒ Cannot access kofort9/sentry repository"
    echo "   ðŸ”§ Check repository permissions"
    exit 1
fi

echo ""

# Check for self-hosted runners
echo "3ï¸âƒ£  Self-Hosted Runners:"
RUNNERS=$(gh api repos/kofort9/sentry/actions/runners --jq '.total_count')
if [ "$RUNNERS" -gt 0 ]; then
    echo "   âœ… Found $RUNNERS self-hosted runner(s)"
    gh api repos/kofort9/sentry/actions/runners --jq '.runners[] | "   ðŸ“‹ \(.name) - \(.status) (\(.os))"'
else
    echo "   âŒ No self-hosted runners found"
    echo "   ðŸ”§ Run: ./scripts/setup-self-hosted-runner.sh"
fi

echo ""

# Check if Ollama is installed
echo "4ï¸âƒ£  Ollama Installation:"
if command -v ollama &> /dev/null; then
    echo "   âœ… Ollama is installed"

    # Check if Ollama service is running
    if curl -sSf http://127.0.0.1:11434/api/tags >/dev/null 2>&1; then
        echo "   âœ… Ollama service is running"

        # Check available models
        MODELS=$(ollama list 2>/dev/null | wc -l)
        echo "   ðŸ“‹ Available models: $((MODELS - 1))"

        if [ "$MODELS" -gt 1 ]; then
            echo "   ðŸ“ Installed models:"
            ollama list | tail -n +2 | sed 's/^/      - /'
        else
            echo "   âš ï¸  No models installed"
            echo "   ðŸ”§ Run: ollama pull llama3.1:8b-instruct-q4_K_M"
        fi
    else
        echo "   âŒ Ollama service is not running"
        echo "   ðŸ”§ Run: ollama serve"
    fi
else
    echo "   âŒ Ollama is not installed"
    echo "   ðŸ”§ Run: brew install ollama"
fi

echo ""

# Check system resources
echo "5ï¸âƒ£  System Resources:"
echo "   ðŸ’¾ Memory: $(free -h | grep Mem | awk '{print $3 "/" $2}' 2>/dev/null || echo "N/A")"
echo "   ðŸ’½ Disk: $(df -h / | tail -1 | awk '{print $3 "/" $2 " (" $5 " used)"}')"
echo "   ðŸ–¥ï¸  OS: $(uname -s) $(uname -m)"

echo ""

# Summary
echo "ðŸ“Š Summary:"
if [ "$RUNNERS" -gt 0 ] && command -v ollama &> /dev/null && curl -sSf http://127.0.0.1:11434/api/tags >/dev/null 2>&1; then
    echo "   âœ… Ready for LLM tests!"
    echo "   ðŸš€ You can now enable LLM tests in your PRs"
else
    echo "   âš ï¸  Setup required:"
    if [ "$RUNNERS" -eq 0 ]; then
        echo "      - Set up self-hosted runner"
    fi
    if ! command -v ollama &> /dev/null; then
        echo "      - Install Ollama"
    fi
    if ! curl -sSf http://127.0.0.1:11434/api/tags >/dev/null 2>&1; then
        echo "      - Start Ollama service"
    fi
fi

echo ""
echo "ðŸ”§ Quick setup commands:"
echo "   ./scripts/setup-self-hosted-runner.sh  # Set up runner"
echo "   brew install ollama                    # Install Ollama"
echo "   ollama serve                           # Start Ollama"
echo "   ollama pull llama3.1:8b-instruct-q4_K_M  # Install models"
